import streamlit as st
import datetime
import asyncio
import os
import subprocess
from diet_minutes_api import DietMinutesAPI
from news_fetcher import NewsFetcher
from script_generator import ScriptGenerator
from komei_scraper import KomeiScraper
from slide_generator import SlideGenerator
from law_fetcher import LawFetcher
from stats_fetcher import StatsFetcher
from settings_manager import load_settings, save_settings
from project_manager import save_project, list_projects, delete_project
import re
import json

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="å›½ä¼šNEWSå°æœ¬", layout="wide")

# ã‚«ã‚¹ã‚¿ãƒ CSSã®æ³¨å…¥ (ã‚·ãƒ³ãƒ—ãƒ«ï¼†ã‚¯ãƒªãƒ¼ãƒ³)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Noto+Sans+JP:wght@400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Inter', 'Noto Sans JP', sans-serif;
    }

    /* ã‚¿ã‚¤ãƒˆãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ (ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ) */
    .title-area {
        margin-bottom: 2rem;
    }
    .title-text {
        font-size: 2.5rem;
        font-weight: 800;
        color: #2196f3;
        line-height: 1.2;
    }
    .subtitle-text {
        font-size: 1rem;
        color: #888;
        margin-top: 5px;
    }

    /* ãƒœã‚¿ãƒ³ã®è§’ä¸¸ */
    div.stButton > button {
        border-radius: 10px;
        transition: all 0.2s ease;
    }
    
    /* ã‚«ãƒ¼ãƒ‰ã®è§’ä¸¸ (ãƒ†ãƒ¼ãƒã®è‰²ã‚’æ´»ã‹ã™ãŸã‚èƒŒæ™¯æŒ‡å®šãªã—) */
    div[data-testid="stVerticalBlockBorderWrapper"] {
        border-radius: 12px !important;
        padding: 1.2rem !important;
    }

    /* ãƒ¢ãƒã‚¤ãƒ«ç”¨èª¿æ•´ */
    @media (max-width: 640px) {
        .title-text { font-size: 1.8rem; }
    }
</style>
""", unsafe_allow_html=True)

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
def clean_script_text(text: str) -> str:
    """å°æœ¬ã‹ã‚‰JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã™ã‚‹"""
    if not text:
        return ""
    # ```json ... ``` ã‚’é™¤å»
    text = re.sub(r"```json.*?```", "", text, flags=re.DOTALL)
    # è£¸ã® JSON é…åˆ—ã£ã½ã„éƒ¨åˆ†ã‚‚é™¤å» (å¿µã®ãŸã‚)
    text = re.sub(r"\[\s*\{.*\}\s*\]", "", text, flags=re.DOTALL)
    return text.strip()

# Playwrightã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
@st.cache_resource
def ensure_playwright_browsers():
    # Streamlit Cloudã®æ¤œçŸ¥ (ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ãƒ‘ã‚¹)
    is_cloud = os.environ.get("STREAMLIT_SERVER_GATHER_USAGE_STATS") is not None or os.path.exists("/home/appuser")
    if is_cloud:
        try:
            # ãƒ–ãƒ©ã‚¦ã‚¶ãŒæ—¢ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ (é«˜é€ŸåŒ–ã®ãŸã‚)
            if not os.path.exists("/home/appuser/.cache/ms-playwright"):
                subprocess.run(["playwright", "install", "chromium"], check=True)
            return True
        except Exception as e:
            st.error(f"Playwrightã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    return True

ensure_playwright_browsers()

# è¨­å®šã®èª­ã¿è¾¼ã¿
saved_settings = load_settings()

st.markdown("""
<div class="title-area">
    <div class="title-text">ğŸ›ï¸ å›½ä¼šNEWSå°æœ¬</div>
    <div class="subtitle-text">æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨å›½ä¼šè­°äº‹éŒ²ã‹ã‚‰ã€é«˜å“è³ªãªè§£èª¬å°æœ¬ã‚’ã€‚</div>
</div>
""", unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®š
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    # settings.json (ãƒ­ãƒ¼ã‚«ãƒ«) ã®èª­ã¿è¾¼ã¿
    saved_settings = load_settings()

    # st.secrets (ã‚¯ãƒ©ã‚¦ãƒ‰) ã¾ãŸã¯ settings.json (ãƒ­ãƒ¼ã‚«ãƒ«) ã‹ã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—
    def get_secret_or_setting(key, setting_key):
        try:
            if key in st.secrets:
                return st.secrets[key]
        except Exception:
            # secrets.toml ãŒå­˜åœ¨ã—ãªã„ã€ã¾ãŸã¯ã‚­ãƒ¼ãŒãªã„å ´åˆã¯ç„¡è¦–ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«è¨­å®šã¸
            pass
        return saved_settings.get(setting_key, "")

    default_openai_key = get_secret_or_setting("OPENAI_API_KEY", "openai_key")
    default_gemini_key = get_secret_or_setting("GEMINI_API_KEY", "gemini_key")
    default_komei_user = get_secret_or_setting("KOMEI_USER", "komei_user")
    default_komei_pass = get_secret_or_setting("KOMEI_PASS", "komei_pass")
    default_estat_id = get_secret_or_setting("ESTAT_APP_ID", "estat_id")
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
    provider = st.selectbox("AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", ["OpenAI", "Gemini"], index=0 if saved_settings.get("provider") == "OpenAI" else 1)
    
    if provider == "OpenAI":
        api_key = st.text_input("OpenAI API Key", type="password", key="openai_key_input", value=default_openai_key)
        model = st.selectbox("ãƒ¢ãƒ‡ãƒ«", ["gpt-4o", "gpt-4o-mini"], index=0 if saved_settings.get("openai_model") == "gpt-4o" else 1)
    else:
        api_key = st.text_input("Gemini API Key", type="password", key="gemini_key_input", value=default_gemini_key)
        model = st.selectbox("ãƒ¢ãƒ‡ãƒ«", [
            "gemini-3-pro-preview", 
            "gemini-3-pro-image-preview", 
            "gemini-2.5-pro"
        ], index=["gemini-3-pro-preview", "gemini-3-pro-image-preview", "gemini-2.5-pro"].index(saved_settings.get("gemini_model", "gemini-3-pro-preview")))
    
    st.divider()
    st.subheader("ğŸ’¡ å¤–éƒ¨é€£æº (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    
    komei_user = st.text_input("KOMEI ID", placeholder="example@komei.jp", value=default_komei_user)
    komei_pass = st.text_input("Password", type="password", value=default_komei_pass)
    komei_article_url = st.text_input("å…¬æ˜è¨˜äº‹URL", placeholder="https://viewer.komei-shimbun.jp/...", value=saved_settings.get("komei_article_url", ""))
    estat_id = st.text_input("e-Stat App ID", placeholder="å–å¾—ã—ãŸIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=default_estat_id, type="password")

    if st.button("ğŸ’¾ è¨­å®šã‚’ä¿å­˜"):
        # å…¥åŠ›ã•ã‚ŒãŸå€¤ï¼ˆã¾ãŸã¯secretsã‹ã‚‰èª­ã¿è¾¼ã¾ã‚ŒãŸå€¤ï¼‰ã‚’ä¿å­˜
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®ç†ç”±ã§secretsã®å€¤ã‚’ãƒ­ãƒ¼ã‚«ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãã“ã¨ã«ãªã‚Šã¾ã™ãŒã€
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¤ºçš„ã«ä¿å­˜ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸå ´åˆãªã®ã§è¨±å®¹ã—ã¾ã™ã€‚
        current_settings = {
            "provider": provider,
            "openai_key": api_key, # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’æ¡ç”¨
            "openai_model": model if provider == "OpenAI" else saved_settings.get("openai_model", "gpt-4o"),
            "gemini_key": api_key, # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’æ¡ç”¨
            "gemini_model": model if provider == "Gemini" else saved_settings.get("gemini_model", "gemini-3-pro-preview"),
            "komei_user": komei_user,
            "komei_pass": komei_pass,
            "komei_article_url": komei_article_url,
            "estat_id": estat_id
        }
        save_settings(current_settings)
        st.success("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

# ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–
tab_main, tab_history = st.tabs(["ğŸš€ å°æœ¬ä½œæˆ", "ğŸ“œ å±¥æ­´ä¸€è¦§"])

with tab_main:
    # 1. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’æœ€ä¸Šéƒ¨ã«é…ç½® (ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ“ãƒªãƒ†ã‚£å‘ä¸Š)
    col1, col2 = st.columns([2, 1])

    if "main_topic_input" not in st.session_state:
        st.session_state["main_topic_input"] = ""

    with col1:
        topic = st.text_input(
            "è­°é¡Œãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ–‡ç« ã§ã®å…¥åŠ›ã‚‚OKï¼ï¼‰", 
            placeholder="ä¾‹ï¼šå›½ä¿é€ƒã‚Œã«ã¤ã„ã¦ç›´è¿‘ã®è©±é¡Œã‚’ã¾ã¨ã‚ã¦",
            key="main_topic_input"
        )
        
    with col2:
        date_range = st.date_input(
            "æœŸé–“æŒ‡å®š",
            value=(datetime.date.today() - datetime.timedelta(days=7), datetime.date.today()),
            help="æƒ…å ±ã‚’å–å¾—ã™ã‚‹å¯¾è±¡æœŸé–“ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )

    # ã‚½ãƒ¼ã‚¹é¸æŠ
    st.markdown("ğŸ” **åé›†ã‚½ãƒ¼ã‚¹ã®é¸æŠ**")
    col_s1, col_s2, col_s3, col_s4, col_s5 = st.columns(5)
    with col_s1:
        use_komei = st.checkbox("å…¬æ˜æ–°è", value=True)
    with col_s2:
        use_diet = st.checkbox("å›½ä¼šè­°äº‹éŒ²", value=True)
    with col_s3:
        use_news = st.checkbox("ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹", value=True)
    with col_s4:
        use_law = st.checkbox("e-Govæ³•ä»¤", value=True)
    with col_s5:
        use_stats = st.checkbox("e-Statçµ±è¨ˆ", value=True)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "current_script" not in st.session_state:
        st.session_state["current_script"] = None
    if "current_news" not in st.session_state:
        st.session_state["current_news"] = []
    if "current_speeches" not in st.session_state:
        st.session_state["current_speeches"] = []
    if "show_trends" not in st.session_state:
        st.session_state["show_trends"] = False
    if "current_model" not in st.session_state:
        st.session_state["current_model"] = "N/A"
    if "current_raw_script" not in st.session_state:
        st.session_state["current_raw_script"] = ""

    # 2. å°æœ¬ç”Ÿæˆãƒœã‚¿ãƒ³
    if st.button("ğŸš€ å°æœ¬ã‚’ç”Ÿæˆã™ã‚‹", type="primary"):
        if not topic:
            st.error("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not api_key:
            st.error(f"{provider}ã®APIã‚­ãƒ¼ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            # å‰å›ã®æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
            st.session_state["current_raw_script"] = ""
            st.session_state["current_script"] = ""
            st.session_state["current_slides_data"] = []
            st.session_state["current_news"] = []
            st.session_state["current_speeches"] = []
            
            try:
                generator = ScriptGenerator(provider, api_key, model)
                
                with st.status(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£æä¸­...", expanded=True) as status:
                    # è‡ªç„¶è¨€èªè§£æã®å®Ÿè¡Œ
                    query_info = generator.analyze_query(topic)
                    search_keywords = ", ".join(query_info["keywords"])
                    st.write(f"ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¾ã—ãŸ: `{search_keywords}`")
                    
                    # æœŸé–“ã®ç¢ºå®š
                    default_start = datetime.date.today() - datetime.timedelta(days=7)
                    user_start = date_range[0]
                    user_end = date_range[1] if len(date_range) == 2 else datetime.date.today()
                    
                    if user_start != default_start:
                        start_date = user_start
                        end_date = user_end
                        st.write(f"ğŸ“… ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®æœŸé–“ã‚’é©ç”¨ã—ã¾ã™: {start_date} ã€œ {end_date}")
                    elif query_info.get("days"):
                        end_date = datetime.date.today()
                        start_date = end_date - datetime.timedelta(days=query_info["days"])
                        st.write(f"ğŸ“… æ–‡ç« ã‹ã‚‰æœŸé–“ã‚’æ¨æ¸¬ã—ã¾ã—ãŸ: {start_date} ã€œ {end_date} ({query_info['days']}æ—¥é–“)")
                    else:
                        start_date = user_start
                        end_date = user_end

                    news_list = []
                    speeches = []

                    # --- 1. å›½ä¼šè­°äº‹éŒ²ã®å–å¾— ---
                    if use_diet:
                        diet_start = end_date - datetime.timedelta(days=365)
                        st.write(f"ğŸ›ï¸ å›½ä¼šè­°äº‹éŒ²ã‚’æ¤œç´¢ä¸­ (èƒŒæ™¯èª¿æŸ»ã®ãŸã‚ 1å¹´å‰ã¾ã§é¡ã‚Šã¾ã™: {diet_start} ã€œ {end_date})...")
                        diet_api = DietMinutesAPI()
                        speeches = diet_api.fetch_speeches(
                            any_keyword=search_keywords,
                            from_date=diet_start.strftime("%Y-%m-%d"),
                            until_date=end_date.strftime("%Y-%m-%d")
                        )
                        st.write(f"âœ… è­°äº‹éŒ²: {len(speeches)}ä»¶å–å¾—")
                    else:
                        st.write("â© å›½ä¼šè­°äº‹éŒ²ã‚’ã‚¹ã‚­ãƒƒãƒ—")

                    # --- 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹RSSã®å–å¾— ---
                    if use_news:
                        st.write(f"ä¸»è¦ãƒ¡ãƒ‡ã‚£ã‚¢ã®RSSã‚’æ¤œç´¢ä¸­...")
                        news_fetcher = NewsFetcher()
                        main_kw = query_info["keywords"][0] if query_info["keywords"] else topic
                        news_list = news_fetcher.fetch_all_news(
                            keyword=main_kw,
                            days=(end_date - start_date).days
                        )
                        st.write(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(news_list)}ä»¶å–å¾— (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {main_kw})")
                    else:
                        st.write("â© ãã®ä»–ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚¹ã‚­ãƒƒãƒ—")

                    # --- 3. å…¬æ˜æ–°èã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ---
                    if use_komei and komei_user and komei_pass:
                        scraper = KomeiScraper()
                        target_urls = []
                        if komei_article_url:
                            target_urls = [komei_article_url]
                        else:
                            st.write("---")
                            k_keywords = query_info.get("keywords", [topic])
                            st.write(f"ğŸ” å…¬æ˜æ–°èã‚’æ¤œç´¢ä¸­ (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å€™è£œ: {', '.join(k_keywords)})...")
                            for kw in k_keywords:
                                f_urls = asyncio.run(scraper.search_articles(kw))
                                if f_urls:
                                    target_urls.extend(f_urls)
                                    st.write(f"âœ… å…¬æ˜æ–°è: ã€Œ{kw}ã€ã§è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                                    break
                        if target_urls:
                            target_urls = list(dict.fromkeys(target_urls))[:3]
                            for idx, url in enumerate(target_urls):
                                st.write(f"ğŸ“„ å…¬æ˜æ–°èè¨˜äº‹ã®å†…å®¹ã‚’æŠ½å‡ºä¸­ ({idx+1}/{len(target_urls)})...")
                                komei_text = asyncio.run(scraper.fetch_article_text(komei_user, komei_pass, url))
                                if komei_text:
                                    news_list.append({
                                        "source": "å…¬æ˜æ–°è",
                                        "title": f"å…¬æ˜æ–°è é–¢é€£è¨˜äº‹ {idx+1}",
                                        "summary": komei_text[:1000] + "...",
                                        "link": url,
                                        "published": datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
                                    })
                                    st.success(f"âœ… å…¬æ˜æ–°è: æˆåŠŸ")
                                else:
                                    st.error(f"âŒ å…¬æ˜æ–°è: å¤±æ•—")
                        elif not komei_article_url:
                            st.info("â„¹ï¸ å…¬æ˜æ–°è: é–¢é€£è¨˜äº‹ãªã—")
                    else:
                        st.write("â© å…¬æ˜æ–°èã‚’ã‚¹ã‚­ãƒƒãƒ—")

                    # --- 4. æ³•ä»¤æƒ…å ±ã®å–å¾— ---
                    law_titles = []
                    if use_law:
                        st.write("e-Govæ³•ä»¤APIã‚’æ¤œç´¢ä¸­...")
                        law_fetcher = LawFetcher()
                        l_keywords = query_info.get("law_keywords", query_info["keywords"])
                        unique_laws = []
                        seen_ids = set()
                        for kw in l_keywords:
                            st.write(f"ğŸ” æ³•ä»¤: ã€Œ{kw}ã€ã§æ¤œç´¢è©¦è¡Œä¸­...")
                            results = law_fetcher.search_laws(kw)
                            if results:
                                for r in results:
                                    if r['id'] not in seen_ids:
                                        unique_laws.append(r)
                                        seen_ids.add(r['id'])
                            if len(unique_laws) >= 5: break
                        law_titles = [f"{r['title']} ({r['number']})" for r in unique_laws[:5]]
                        st.write(f"âœ… æ³•ä»¤: {len(law_titles)}ä»¶ç‰¹å®š")

                    # --- 5. çµ±è¨ˆæƒ…å ±ã®å–å¾— ---
                    stats_summaries = []
                    if use_stats:
                        st.write("e-Statçµ±è¨ˆAPIã‚’æ¤œç´¢ä¸­...")
                        stats_fetcher = StatsFetcher(app_id=estat_id)
                        s_keywords = query_info.get("stats_keywords", query_info["keywords"])
                        unique_stats = []
                        seen_ids = set()
                        for kw in s_keywords:
                            st.write(f"ğŸ“Š çµ±è¨ˆ: ã€Œ{kw}ã€ã§æ¤œç´¢è©¦è¡Œä¸­...")
                            results = stats_fetcher.search_stats(kw)
                            if results:
                                for r in results:
                                    if r['id'] not in seen_ids:
                                        unique_stats.append(r)
                                        seen_ids.add(r['id'])
                            if len(unique_stats) >= 5: break
                        stats_summaries = [f"{r['title']} ({r['org']})" for r in unique_stats[:5]]
                        st.write(f"âœ… çµ±è¨ˆ: {len(stats_summaries)}ä»¶ç‰¹å®š")

                    # --- 6. å°æœ¬ç”Ÿæˆ ---
                    st.write(f"AI ({model}) ãŒå°æœ¬ã‚’åŸ·ç­†ä¸­...")
                    generator = ScriptGenerator(provider=provider, api_key=api_key, model=model)
                    generated_text = generator.generate(topic, news_list, speeches, law_titles, stats_summaries)
                    slides_data = generator.extract_json_from_response(generated_text)
                    
                    st.session_state["current_raw_script"] = generated_text
                    st.session_state["current_script"] = clean_script_text(generated_text)
                    st.session_state["current_slides_data"] = slides_data
                    st.session_state["current_news"] = news_list
                    st.session_state["current_speeches"] = speeches
                    st.session_state["current_topic"] = topic
                    st.session_state["current_provider"] = provider
                    st.session_state["current_model"] = model
                    
                    status.update(label="å®Œäº†ï¼", state="complete", expanded=False)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ç”Ÿæˆçµæœã®è¡¨ç¤º
    if st.session_state["current_script"]:
        st.divider()
        st.subheader(f"ğŸ“ ç”Ÿæˆã•ã‚ŒãŸè¦ç´„å°æœ¬ ({st.session_state['current_model']})")
        
        # å°æœ¬ã®ç·¨é›†ãƒ»é–²è¦§
        new_script = st.text_area(
            "å°æœ¬å†…å®¹ (ç›´æ¥ç·¨é›†ã‚‚å¯èƒ½ã§ã™)", 
            value=st.session_state["current_script"], 
            height=400,
            key="display_script_area"
        )
        st.session_state["current_script"] = new_script

        # --- å°æœ¬ã®å†æ§‹æˆï¼ˆRefinementï¼‰ ---
        st.markdown("ğŸª„ **AIã«å†æ§‹æˆã‚’ä¾é ¼ã™ã‚‹**")
        refine_instruction = st.text_input(
            "è¿½åŠ ã®æŒ‡ç¤ºï¼ˆä¾‹ï¼šã‚‚ã£ã¨å…·ä½“ä¾‹ã‚’å¢—ã‚„ã—ã¦ã€ãƒˆãƒ¼ãƒ³ã‚’æ˜ã‚‹ãã—ã¦ã€è­°è«–ã‚’æ·±æ˜ã‚Šã—ã¦ï¼‰",
            placeholder="ã“ã“ã«æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
            key="refine_input"
        )
        
        if st.button("âœ¨ å†æ§‹æˆã‚’å®Ÿè¡Œ"):
            if not refine_instruction:
                st.warning("æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    with st.status("å°æœ¬ã‚’å†æ§‹æˆä¸­...", expanded=True) as status:
                        generator = ScriptGenerator(
                            provider=st.session_state["current_provider"], 
                            api_key=api_key, 
                            model=st.session_state["current_model"]
                        )
                        # æœ€æ–°ã®(ç·¨é›†ã•ã‚ŒãŸ)å°æœ¬ã¨ã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›ã¦å†é€
                        new_raw_text = generator.refine(
                            st.session_state["current_raw_script"], 
                            refine_instruction
                        )
                        
                        # æ›´æ–°
                        st.session_state["current_raw_script"] = new_raw_text
                        st.session_state["current_script"] = clean_script_text(new_raw_text)
                        st.session_state["current_slides_data"] = generator.extract_json_from_response(new_raw_text)
                        
                        status.update(label="å†æ§‹æˆå®Œäº†ï¼", state="complete")
                    st.rerun()
                except Exception as e:
                    st.error(f"å†æ§‹æˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        col_save, _ = st.columns([1, 4])
        with col_save:
            if st.button("ğŸ’¾ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿å­˜ã™ã‚‹"):
                path = save_project(
                    st.session_state["current_topic"], 
                    st.session_state["current_raw_script"], # ä¿å­˜ã¯ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿
                    st.session_state["current_news"], 
                    st.session_state["current_speeches"], 
                    st.session_state["current_provider"], 
                    st.session_state["current_model"]
                )
                st.success(f"ä¿å­˜å®Œäº†: {path}")

        # ãƒ—ãƒ¬ã‚¼ãƒ³è³‡æ–™ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
        if st.session_state.get("current_slides_data"):
            st.divider()
            st.subheader("ğŸ“Š ãƒ—ãƒ¬ã‚¼ãƒ³è³‡æ–™ã®ç”Ÿæˆ")
            st.info("å°æœ¬ã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚¹ãƒ©ã‚¤ãƒ‰è³‡æ–™ã§ã™ã€‚")
            
            presentation_title = f"{st.session_state['current_topic']}ã«é–¢ã™ã‚‹è§£èª¬"
            slide_gen = SlideGenerator()
            pptx_path = slide_gen.create_slides(presentation_title, st.session_state["current_slides_data"])
            
            with open(pptx_path, "rb") as f:
                st.download_button(
                    label="ğŸ“¥ ãƒ—ãƒ¬ã‚¼ãƒ³è³‡æ–™(.pptx)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=f,
                    file_name=f"presentation_{datetime.date.today()}.pptx",
                    mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                )
            
            with st.expander("ğŸ“Š ã‚¹ãƒ©ã‚¤ãƒ‰æ§‹æˆãƒ‡ãƒ¼ã‚¿ (JSON) ã‚’ç¢ºèª"):
                st.json(st.session_state["current_slides_data"])

        with st.expander("å–å¾—ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚½ãƒ¼ã‚¹ï¼‰ã®ç¢ºèª"):
            tab_n, tab_s = st.tabs(["ğŸ—ï¸ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»è¨˜äº‹", "ğŸ›ï¸ å›½ä¼šè­°äº‹éŒ²"])
            with tab_n:
                if not st.session_state["current_news"]:
                    st.info("å–å¾—ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                for n in st.session_state["current_news"]:
                    with st.container(border=True):
                        st.write(f"**[{n['source']}] {n['title']}**")
                        st.caption(f"ãƒªãƒ³ã‚¯: {n.get('link', 'N/A')}")
            with tab_s:
                if not st.session_state["current_speeches"]:
                    st.info("å–å¾—ã•ã‚ŒãŸè­°äº‹éŒ²ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                for s in st.session_state["current_speeches"]:
                    with st.container(border=True):
                        st.write(f"**{s.get('speaker')}** ({s.get('date')} - {s.get('nameOfMeeting')})")
                        st.write(s.get('speech'))

    st.divider()

    # ã‚¿ã‚°ã‚¯ãƒªãƒƒã‚¯æ™‚ã®è¿½åŠ ãƒ­ã‚¸ãƒƒã‚¯ (callbackã§ä½¿ç”¨)
    def on_tag_click(new_tag):
        current = st.session_state.get("main_topic_input", "")
        if current:
            # ã™ã§ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            tags = [t.strip() for t in current.split(",")]
            if new_tag not in tags:
                st.session_state["main_topic_input"] = f"{current}, {new_tag}"
        else:
            st.session_state["main_topic_input"] = new_tag

    @st.cache_data(ttl=3600)  # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æˆ»ã™
    def fetch_trending_info(_provider, _api_key, _model):
        async def _fetch():
            fetcher = NewsFetcher()
            scraper = KomeiScraper()
            generator = ScriptGenerator(provider=_provider, api_key=_api_key, model=_model)
            
            # 1. è¦‹å‡ºã—å–å¾— (å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
            res_general = []
            res_komei = []
            err_general = None
            err_komei = None
            
            try:
                res_general = await asyncio.to_thread(fetcher.get_trending_headlines)
            except Exception as e:
                err_general = str(e)
            
            try:
                res_komei = await scraper.get_trending_headlines()
            except Exception as e:
                err_komei = str(e)
            
            # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º (å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
            gen_tags = []
            kom_tags = []
            
            if res_general:
                try:
                    gen_tags = await asyncio.to_thread(generator.extract_keyword_tags, res_general)
                except Exception as e:
                    err_general = f"Tags Error: {e}" if not err_general else f"{err_general} | Tags Error: {e}"
            
            if res_komei:
                try:
                    kom_tags = await asyncio.to_thread(generator.extract_keyword_tags, res_komei)
                except Exception as e:
                    err_komei = f"Tags Error: {e}" if not err_komei else f"{err_komei} | Tags Error: {e}"

            return {
                "general": {"tags": gen_tags, "headlines": res_general, "error": err_general},
                "komei": {"tags": kom_tags, "headlines": res_komei, "error": err_komei}
            }
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            import nest_asyncio
            nest_asyncio.apply()
            return loop.run_until_complete(_fetch())
        except Exception as e:
            # st.error ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã§ã¯ä½¿ãˆãªã„ãŸã‚ warning ã§è¿”ã™ã‹ç©ºã«ã™ã‚‹
            # å®Ÿéš›ã«ã¯å‘¼ã³å‡ºã—å…ƒã§è¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¿½åŠ å¯èƒ½
            return {
                "general": {"tags": [], "headlines": []}, 
                "komei": {"tags": [], "headlines": []},
                "error": str(e)
            }

    st.divider()

    # 3. æ³¨ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (æ‰‹å‹•ã¾ãŸã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼å½¢å¼)
    st.markdown("### ğŸ”¥ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ³¨ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
    
    if not st.session_state.get("show_trends", False):
        if st.button("ğŸ” ä»Šæ³¨ç›®ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã‚€", use_container_width=True):
            st.session_state["show_trends"] = True
            st.rerun()
    else:
        # APIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã®ã¿ã‚¿ã‚°ã‚’è¡¨ç¤º
        if not api_key:
            st.warning(f"{provider} ã® API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒˆãƒ¬ãƒ³ãƒ‰ã®æŠ½å‡ºã«ã¯ AI é€£æºãŒå¿…è¦ã§ã™ã€‚")
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚­ãƒ¼ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€Streamlit Cloud ã® Secrets ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            st.session_state["show_trends"] = False
        else:
            with st.spinner("ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—ä¸­..."):
                trend_data = fetch_trending_info(provider, api_key, model)
                
                # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°è¡¨ç¤º
                if "error" in trend_data:
                    st.error(f"ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {trend_data['error']}")
                    st.info("Playwright ã®èµ·å‹•ã«å¤±æ•—ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã®åˆ¶é™ãªã©ï¼‰ã€‚")
            
            # 1. ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            with st.container(border=True):
                st.markdown("ğŸ—ï¸ **ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ³¨ç›®ãƒ¯ãƒ¼ãƒ‰**")
                tags = trend_data["general"]["tags"]
                if tags:
                    tag_cols = st.columns(len(tags))
                    for i, tag in enumerate(tags):
                        tag_cols[i].button(
                            f"#{tag}", 
                            key=f"tag_gen_{tag}", 
                            use_container_width=True,
                            on_click=on_tag_click,
                            args=(tag,)
                        )
                
                headlines = trend_data["general"]["headlines"]
                if headlines:
                    for h in headlines[:3]:
                        st.markdown(f"- <small>{h}</small>", unsafe_allow_html=True)
                    if len(headlines) > 3:
                        with st.expander("ã‚‚ã£ã¨è¦‹ã‚‹"):
                            for h in headlines[3:]:
                                st.markdown(f"- <small>{h}</small>", unsafe_allow_html=True)

            # 2. å…¬æ˜æ–°èã‚»ã‚¯ã‚·ãƒ§ãƒ³
            with st.container(border=True):
                st.markdown("ğŸ¢ **å…¬æ˜æ–°èã®æ³¨ç›®ãƒ¯ãƒ¼ãƒ‰**")
                
                # å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ã®è¡¨ç¤º
                if trend_data["komei"].get("error"):
                    st.warning(f"å–å¾—ã‚¨ãƒ©ãƒ¼: {trend_data['komei']['error']}")
                
                tags = trend_data["komei"]["tags"]
                if tags:
                    tag_cols = st.columns(len(tags))
                    for i, tag in enumerate(tags):
                        tag_cols[i].button(
                            f"#{tag}", 
                            key=f"tag_kom_{tag}", 
                            use_container_width=True,
                            on_click=on_tag_click,
                            args=(tag,)
                        )
                
                headlines = trend_data["komei"]["headlines"]
                if headlines:
                    for h in headlines[:3]:
                        st.markdown(f"- <small>{h}</small>", unsafe_allow_html=True)
                    if len(headlines) > 3:
                        with st.expander("ã‚‚ã£ã¨è¦‹ã‚‹"):
                            for h in headlines[3:]:
                                st.markdown(f"- <small>{h}</small>", unsafe_allow_html=True)
            
            if st.button("ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’é–‰ã˜ã‚‹"):
                st.session_state["show_trends"] = False
                st.rerun()

with tab_history:
    st.header("ğŸ“œ ä¿å­˜æ¸ˆã¿ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    history = list_projects()
    
    if not history:
        st.info("ä¿å­˜ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        for proj in history:
            with st.container(border=True):
                col_h1, col_h2, col_h3 = st.columns([3, 2, 1])
                with col_h1:
                    st.write(f"**ãƒˆãƒ”ãƒƒã‚¯: {proj['topic']}**")
                    st.caption(f"æ—¥æ™‚: {proj['timestamp']} | ãƒ¢ãƒ‡ãƒ«: {proj['model']}")
                with col_h2:
                    if st.button("å°æœ¬ã‚’è¡¨ç¤º", key=f"view_{proj['filename']}"):
                        st.session_state["view_proj"] = proj
                        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã«ã‚‚åæ˜ ã•ã›ã‚‹ (ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½)
                        st.session_state["current_topic"] = proj.get("topic", "")
                        st.session_state["current_script"] = proj.get("script", "")
                        st.session_state["current_raw_script"] = proj.get("raw_script", proj.get("script", ""))
                        st.session_state["current_news"] = proj.get("news_list", [])
                        st.session_state["current_speeches"] = proj.get("diet_speeches", [])
                        st.session_state["current_slides_data"] = proj.get("slides_data", [])
                        st.session_state["current_model"] = proj.get("model", "N/A")
                        st.session_state["current_provider"] = proj.get("provider", "N/A")
                        st.success(f"ã€Œ{proj['topic']}ã€ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚ã€Œå°æœ¬ä½œæˆã€ã‚¿ãƒ–ã§ç·¨é›†ã§ãã¾ã™ã€‚")
                with col_h3:
                    if st.button("å‰Šé™¤", key=f"del_{proj['filename']}", type="secondary"):
                        delete_project(proj['filename'])
                        st.rerun()

    if "view_proj" in st.session_state:
        proj = st.session_state["view_proj"]
        st.divider()
        st.subheader(f"ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {proj['topic']}")
        st.text_area("ä¿å­˜ã•ã‚ŒãŸå°æœ¬", value=proj['script'], height=400)
        
        with st.expander("ä¿å­˜æ™‚ã®ã‚½ãƒ¼ã‚¹ã‚’ç¢ºèª"):
            st.write(f"AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {proj['provider']} ({proj['model']})")
            st.write(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(proj.get('news_list', []))}ä»¶")
            st.write(f"è­°äº‹éŒ²æ•°: {len(proj.get('diet_speeches', []))}ä»¶")
            if st.button("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’é–‰ã˜ã‚‹"):
                del st.session_state["view_proj"]
                st.rerun()

# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.caption("Powered by å›½ä¼šè­°äº‹éŒ²æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ API & OpenAI/Google Gemini")
